{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "046e9fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8c7bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MEMORY = '3G'\n",
    "\n",
    "# Initialize a spark session.\n",
    "conf = pyspark.SparkConf().setMaster('local[2]')\\\n",
    "        .set('spark.executor.heartbeatInterval', 10000) \\\n",
    "        .set('spark.network.timeout', 10000) \\\n",
    "        .set(\"spark.core.connection.ack.wait.timeout\", \"3600\") \\\n",
    "        .set(\"spark.executor.memory\", MAX_MEMORY) \\\n",
    "        .set(\"spark.driver.memory\", MAX_MEMORY)\n",
    "                                     \n",
    "# Firstly we create sparkSession (like a container)\n",
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Pyspark EDA\") \\\n",
    "        .config(conf=conf) \\\n",
    "        .getOrCreate()\n",
    "    return spark\n",
    "\n",
    "spark = init_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb187c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+---------+\n",
      "|    Name|       Job Profile|     City|\n",
      "+--------+------------------+---------+\n",
      "|Shivansh|    Data Scientist|    Noida|\n",
      "|    null|Software Developer|     null|\n",
      "|   Swati|      Data Analyst|Hyderabad|\n",
      "|    null|              null|    Noida|\n",
      "|   Arpit| Android Developer| Banglore|\n",
      "|    null|              null|     null|\n",
      "+--------+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_data = [(\"Shivansh\", \"Data Scientist\", \"Noida\"),\n",
    "              (None, \"Software Developer\", None),\n",
    "              (\"Swati\", \"Data Analyst\", \"Hyderabad\"),\n",
    "              (None, None, \"Noida\"),\n",
    "              (\"Arpit\", \"Android Developer\", \"Banglore\"),\n",
    "              (None, None, None)]\n",
    "\n",
    "schema = [\"Name\", \"Job Profile\", \"City\"]\n",
    "\n",
    "# calling function to create dataframe\n",
    "df = spark.createDataFrame(input_data, schema)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbeffb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_col_miss_func(df):\n",
    "    \n",
    "    from pyspark.sql.functions import format_number, lit, concat, count\n",
    "    from pyspark.sql.functions import when, isnan\n",
    "    pd.set_option('max_columns', None)\n",
    "    \n",
    "    print('========================================================')\n",
    "    print('======================SAMPLE OF DATAFRAME===============')\n",
    "    print('========================================================')\n",
    "    \n",
    "    sample= df.limit(2).toPandas()\n",
    "    print(sample)\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    print('========================================================')\n",
    "    print('======================SCHEMA OF DATAFRAME===============')\n",
    "    print('========================================================')    \n",
    "    \n",
    "    df.printSchema()\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print()    \n",
    "    \n",
    "    col_cnt = len(df.columns)\n",
    "\n",
    "\n",
    "    missing_val = df.withColumn('miss_cnt', sum(\\\n",
    "            when((col(column_name) == \"\" ) | (col(column_name).isNull()) | (isnan(col(column_name))),1)\\\n",
    "                 .otherwise(0) for column_name in df.columns))\n",
    "\n",
    "    missing_percent_df = missing_val.withColumn('miss_percent',concat(format_number(((col('miss_cnt')/col_cnt) * 100),2),lit('%')))\n",
    "    \n",
    "    print('========================================================')\n",
    "    print('==============MISSING % OF DATAFRAME=====================')\n",
    "    print('========================================================')   \n",
    "    \n",
    "    missing_percent_df.show()\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print()     \n",
    "        \n",
    "    \n",
    "    missing_percent_df.select('miss_cnt','miss_percent').filter(col('miss_cnt') > 3)\n",
    "\n",
    "    missing_percent_col = df.select([ \\\n",
    "                                count( \\\n",
    "                                  when((col(c) == \"\" ) | \\\n",
    "                                    (col(c).isNull()) | \\\n",
    "                                    (isnan(col(c))), c)).alias(c) \\\n",
    "                                    for c in df.columns])\n",
    "\n",
    "    #missing_percent_col.toPandas()\n",
    "    \n",
    "    print('========================================================')\n",
    "    print('==============MISSING IN COLUMN OF DATAFRAME============')\n",
    "    print('========================================================')   \n",
    "    \n",
    "    print(missing_percent_col.show())\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print()     \n",
    "    \n",
    "    print('========================================================')\n",
    "    print('======================SUMMARY OF DATAFRAME============')\n",
    "    print('========================================================')       \n",
    "    \n",
    "    summary = df.describe().toPandas()\n",
    "    print(summary)\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02fb0587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================\n",
      "======================SAMPLE OF DATAFRAME===============\n",
      "========================================================\n",
      "       Name         Job Profile   City\n",
      "0  Shivansh      Data Scientist  Noida\n",
      "1      None  Software Developer   None\n",
      "\n",
      "\n",
      "\n",
      "========================================================\n",
      "======================SCHEMA OF DATAFRAME===============\n",
      "========================================================\n",
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Job Profile: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "========================================================\n",
      "==============MISSING % OF DATAFRAME=====================\n",
      "========================================================\n",
      "+--------+------------------+---------+--------+------------+\n",
      "|    Name|       Job Profile|     City|miss_cnt|miss_percent|\n",
      "+--------+------------------+---------+--------+------------+\n",
      "|Shivansh|    Data Scientist|    Noida|       0|       0.00%|\n",
      "|    null|Software Developer|     null|       2|      66.67%|\n",
      "|   Swati|      Data Analyst|Hyderabad|       0|       0.00%|\n",
      "|    null|              null|    Noida|       2|      66.67%|\n",
      "|   Arpit| Android Developer| Banglore|       0|       0.00%|\n",
      "|    null|              null|     null|       3|     100.00%|\n",
      "+--------+------------------+---------+--------+------------+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "========================================================\n",
      "==============MISSING IN COLUMN OF DATAFRAME============\n",
      "========================================================\n",
      "+----+-----------+----+\n",
      "|Name|Job Profile|City|\n",
      "+----+-----------+----+\n",
      "|   3|          2|   2|\n",
      "+----+-----------+----+\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "========================================================\n",
      "======================SUMMARY OF DATAFRAME============\n",
      "========================================================\n",
      "  summary   Name         Job Profile      City\n",
      "0   count      3                   4         4\n",
      "1    mean   None                None      None\n",
      "2  stddev   None                None      None\n",
      "3     min  Arpit   Android Developer  Banglore\n",
      "4     max  Swati  Software Developer     Noida\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row_col_miss_func(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
