{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e2fb89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.appName('Windows Function').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e59f0cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-E8SRJD9:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x22d7ee80d90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "155e0be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|Age|Department|Salary|\n",
      "+-------+---+----------+------+\n",
      "|  Sneha| 36|   Finance| 10000|\n",
      "|   Jeny| 26|   Finance|  3900|\n",
      "|  Kunal| 25|   Finance|  3000|\n",
      "|Srishti| 46|Management|  3300|\n",
      "| Rakesh| 38| Marketing|  7000|\n",
      "| Hitesh| 30| Marketing|  3000|\n",
      "|Kailash| 29| Marketing|  2000|\n",
      "|  Meena| 33|     Sales|  4600|\n",
      "| Sharad| 39|     Sales|  4100|\n",
      "|  Robin| 40|     Sales|  4100|\n",
      "|    Ram| 28|     Sales|  3000|\n",
      "|    Ram| 28|     Sales|  3000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# sample data for dataframe\n",
    "sampleData = ((\"Ram\", 28, \"Sales\", 3000),\n",
    "              (\"Meena\", 33, \"Sales\", 4600),\n",
    "              (\"Robin\", 40, \"Sales\", 4100),\n",
    "              (\"Kunal\", 25, \"Finance\", 3000),\n",
    "              (\"Sneha\", 36, \"Finance\", 10000),\n",
    "              (\"Ram\", 28, \"Sales\", 3000),\n",
    "              (\"Srishti\", 46, \"Management\", 3300),\n",
    "              (\"Jeny\", 26, \"Finance\", 3900),\n",
    "              (\"Hitesh\", 30, \"Marketing\", 3000),\n",
    "              (\"Kailash\", 29, \"Marketing\", 2000),\n",
    "              (\"Rakesh\", 38, \"Marketing\", 7000),\n",
    "              (\"Sharad\", 39, \"Sales\", 4100)\n",
    "              )\n",
    " \n",
    "schema = StructType([\n",
    "            StructField(\"Name\", StringType(), False),\n",
    "            StructField(\"Age\",  IntegerType(), False),\n",
    "            StructField(\"Department\", StringType(), False),\n",
    "            StructField(\"Salary\", IntegerType(), False)\n",
    "            ])\n",
    "\n",
    "df = spark.createDataFrame(sampleData,schema)\n",
    "df = df.orderBy(col('Department'), desc(col('Salary')))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34ea6b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|Department|max(Salary)|\n",
      "+----------+-----------+\n",
      "|     Sales|       4600|\n",
      "|   Finance|      10000|\n",
      "|Management|       3300|\n",
      "| Marketing|       7000|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) Find the highest salary of each department\n",
    "max_sal_dept = df.groupBy(col('Department')).agg(max(col('Salary')))\n",
    "max_sal_dept.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eb4fa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+----------+\n",
      "|   Name|Age|Department|Salary|Row_number|\n",
      "+-------+---+----------+------+----------+\n",
      "|  Sneha| 36|   Finance| 10000|         1|\n",
      "|Srishti| 46|Management|  3300|         1|\n",
      "| Rakesh| 38| Marketing|  7000|         1|\n",
      "|  Meena| 33|     Sales|  4600|         1|\n",
      "+-------+---+----------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2) How to get entire row\n",
    "windowspec = Window.partitionBy('Department').orderBy(df['Salary'].desc())\n",
    "df_with_row_number = df.withColumn('Row_number', row_number().over(windowspec))\n",
    "\n",
    "max_salary_dept = df_with_row_number.filter(df_with_row_number['Row_number'] == 1)\n",
    "max_salary_dept.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98d368c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|Age|Department|Salary|\n",
      "+-------+---+----------+------+\n",
      "|  Sneha| 36|   Finance| 10000|\n",
      "|   Jeny| 26|   Finance|  3900|\n",
      "|Srishti| 46|Management|  3300|\n",
      "| Rakesh| 38| Marketing|  7000|\n",
      "| Hitesh| 30| Marketing|  3000|\n",
      "|  Meena| 33|     Sales|  4600|\n",
      "|  Robin| 40|     Sales|  4100|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3) How to get first two highest salary\n",
    "\n",
    "max2_salary_dept = df_with_row_number.filter(df_with_row_number['Row_number'] <= 2).drop('Row_number')\n",
    "max2_salary_dept.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38eb06c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|Age|Department|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Jeny| 26|   Finance|  3900|\n",
      "|Hitesh| 30| Marketing|  3000|\n",
      "| Robin| 40|     Sales|  4100|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4) How to get second highest salary\n",
    "\n",
    "top2nd_salary_dept = df_with_row_number.filter(df_with_row_number['Row_number'] == 2)\n",
    "top2nd_salary_dept.drop('Row_number').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a460ebe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\spark\\spark-3.3.0-bin-hadoop3\\spark-3.3.0-bin-hadoop3\\python\\pyspark\\sql\\dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# find how far the salary is from avergae salary of each department\n",
    "\n",
    "df.registerTempTable('temp_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98120d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+----------+---------------------+\n",
      "|   Name|Age|Department|Salary|avg_salary|differnce_sal_avg_sal|\n",
      "+-------+---+----------+------+----------+---------------------+\n",
      "|    Ram| 28|     Sales|  3000|    3760.0|               -760.0|\n",
      "|  Meena| 33|     Sales|  4600|    3760.0|                840.0|\n",
      "|  Robin| 40|     Sales|  4100|    3760.0|                340.0|\n",
      "|    Ram| 28|     Sales|  3000|    3760.0|               -760.0|\n",
      "|  Kunal| 25|   Finance|  3000|    5633.0|              -2633.0|\n",
      "|  Sneha| 36|   Finance| 10000|    5633.0|               4367.0|\n",
      "|Srishti| 46|Management|  3300|    3300.0|                  0.0|\n",
      "|   Jeny| 26|   Finance|  3900|    5633.0|              -1733.0|\n",
      "| Hitesh| 30| Marketing|  3000|    4000.0|              -1000.0|\n",
      "| Sharad| 39|     Sales|  4100|    3760.0|                340.0|\n",
      "|Kailash| 29| Marketing|  2000|    4000.0|              -2000.0|\n",
      "| Rakesh| 38| Marketing|  7000|    4000.0|               3000.0|\n",
      "+-------+---+----------+------+----------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_average_sal = df.groupBy('Department').agg(round(avg(col('Salary')),0).alias('avg_salary'))\n",
    "df_average_sal = df_average_sal.withColumnRenamed('Department', 'avg_department')\n",
    "df_join_avg = df.join(df_average_sal, df['Department'] == df_average_sal['avg_department'], 'inner').drop('avg_department')\n",
    "diff_sal_avg_sal = df_join_avg.withColumn('differnce_sal_avg_sal', (col('Salary') - col('avg_salary')))\n",
    "diff_sal_avg_sal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf6a2a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|Age|Department|Salary|\n",
      "+-------+---+----------+------+\n",
      "|  Sneha| 36|   Finance| 10000|\n",
      "|   Jeny| 26|   Finance|  3900|\n",
      "|  Kunal| 25|   Finance|  3000|\n",
      "|Srishti| 46|Management|  3300|\n",
      "| Rakesh| 38| Marketing|  7000|\n",
      "| Hitesh| 30| Marketing|  3000|\n",
      "|Kailash| 29| Marketing|  2000|\n",
      "| Sharad| 39|     Sales|  4100|\n",
      "|  Robin| 40|     Sales|  4100|\n",
      "|    Ram| 28|     Sales|  3000|\n",
      "|  Meena| 33|     Sales|  3000|\n",
      "|   Rama| 28|     Sales|  1000|\n",
      "+-------+---+----------+------+\n",
      "\n",
      "+-------+---+----------+------+----+---------+-----+----+---------------+-----------------------+-----------+\n",
      "|   Name|Age|Department|Salary|Rank|DenseRank|  Lag|Lead|Cummulative_Sum|Cummulative_distibution|PercentRank|\n",
      "+-------+---+----------+------+----+---------+-----+----+---------------+-----------------------+-----------+\n",
      "|  Kunal| 25|   Finance|  3000|   3|        3| 3900|null|          16900|                    1.0|        0.0|\n",
      "|   Jeny| 26|   Finance|  3900|   2|        2|10000|3000|          13900|     0.6666666666666666|        0.5|\n",
      "|  Sneha| 36|   Finance| 10000|   1|        1| null|3900|          10000|     0.3333333333333333|        1.0|\n",
      "|Srishti| 46|Management|  3300|   1|        1| null|null|           3300|                    1.0|        0.0|\n",
      "|Kailash| 29| Marketing|  2000|   3|        3| 3000|null|          12000|                    1.0|        0.0|\n",
      "| Hitesh| 30| Marketing|  3000|   2|        2| 7000|2000|          10000|     0.6666666666666666|        0.5|\n",
      "| Rakesh| 38| Marketing|  7000|   1|        1| null|3000|           7000|     0.3333333333333333|        1.0|\n",
      "|   Rama| 28|     Sales|  1000|   5|        3| 3000|null|          15200|                    1.0|        0.0|\n",
      "|    Ram| 28|     Sales|  3000|   3|        2| 4100|3000|          14200|                    0.8|       0.25|\n",
      "|  Meena| 33|     Sales|  3000|   3|        2| 3000|1000|          14200|                    0.8|       0.25|\n",
      "|  Robin| 40|     Sales|  4100|   1|        1| null|4100|           8200|                    0.4|       0.75|\n",
      "| Sharad| 39|     Sales|  4100|   1|        1| 4100|3000|           8200|                    0.4|       0.75|\n",
      "+-------+---+----------+------+----+---------+-----+----+---------------+-----------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the rank and dense rank\n",
    "# The rank function assigns a unique rank to each row based on the specified ordering. \n",
    "# If multiple rows have the same \"Salary,\" they will get the same rank, and the next rank will be skipped.\n",
    "\n",
    "#The dense_rank function is similar to rank but doesn't skip ranks in case of ties. If multiple rows have the same \"Salary,\"\n",
    "#they will get the same rank, and the next rank will continue without skipping.\n",
    "\n",
    "#Lag -This column contains the salary of the previous row within each department based on the ascending order of salaries.\n",
    "#Lead - This column contains the salary of the next row within each department based on the descending order of salaries.\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# sample data for dataframe\n",
    "sampleData = ((\"Ram\", 28, \"Sales\", 3000),\n",
    "              (\"Meena\", 33, \"Sales\", 3000),\n",
    "              (\"Robin\", 40, \"Sales\", 4100),\n",
    "              (\"Kunal\", 25, \"Finance\", 3000),\n",
    "              (\"Sneha\", 36, \"Finance\", 10000),\n",
    "              (\"Rama\", 28, \"Sales\", 1000),\n",
    "              (\"Srishti\", 46, \"Management\", 3300),\n",
    "              (\"Jeny\", 26, \"Finance\", 3900),\n",
    "              (\"Hitesh\", 30, \"Marketing\", 3000),\n",
    "              (\"Kailash\", 29, \"Marketing\", 2000),\n",
    "              (\"Rakesh\", 38, \"Marketing\", 7000),\n",
    "              (\"Sharad\", 39, \"Sales\", 4100)\n",
    "              )\n",
    " \n",
    "schema = StructType([\n",
    "            StructField(\"Name\", StringType(), False),\n",
    "            StructField(\"Age\",  IntegerType(), False),\n",
    "            StructField(\"Department\", StringType(), False),\n",
    "            StructField(\"Salary\", IntegerType(), False)\n",
    "            ])\n",
    "\n",
    "df = spark.createDataFrame(sampleData,schema)\n",
    "df = df.orderBy(col('Department'), desc(col('Salary')))\n",
    "df.show()\n",
    "\n",
    "windowspec = Window.partitionBy('Department').orderBy(df['Salary'].desc())\n",
    "df = df \\\n",
    "    .withColumn('Rank', rank().over(windowspec)) \\\n",
    "    .withColumn('DenseRank', dense_rank().over(windowspec)) \\\n",
    "    .withColumn('Lag', lag('Salary').over(windowspec)) \\\n",
    "    .withColumn('Lead', lead('Salary').over(windowspec)) \\\n",
    "    .withColumn('Cummulative_Sum', sum('Salary').over(windowspec)) \\\n",
    "    .withColumn('Cummulative_distibution', cume_dist().over(windowspec)) \\\n",
    "    .withColumn(\"PercentRank\", percent_rank().over(windowSpec))\n",
    "    \n",
    "df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ab0af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
